{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d991b9",
   "metadata": {},
   "source": [
    "# 0. GPU check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cdef0e",
   "metadata": {},
   "source": [
    "* 이 코드는 Nvidia GPU를 사용하는 컴퓨터에서, train / test 데이터가 분리되어있는 csv 파일을 사용하는 것을 전제로 작성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7101f6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:29.438075Z",
     "start_time": "2022-10-14T08:27:29.006830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_count: 1\n",
      "device 0 capability (8, 6)\n",
      "device 0 name NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(\"device_count: {}\".format(device_count))\n",
    "    for device_num in range(device_count):\n",
    "        print(\"device {} capability {}\".format(\n",
    "            device_num,\n",
    "            torch.cuda.get_device_capability(device_num)))\n",
    "        print(\"device {} name {}\".format(\n",
    "            device_num, \n",
    "            torch.cuda.get_device_name(device_num)))\n",
    "else:\n",
    "    print(\"no cuda device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b0d645",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:29.441065Z",
     "start_time": "2022-10-14T08:27:29.439174Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() :\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else : \n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb22c08c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:29.487814Z",
     "start_time": "2022-10-14T08:27:29.441821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 428 MB.\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n",
    "    \n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20ba44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T05:02:40.544338Z",
     "start_time": "2022-09-22T05:02:40.539520Z"
    }
   },
   "source": [
    "* 모델 훈련과정에서 GPU 메모리 용량 초과 시, 개발서버 콘솔에서 직접 `nvidia-smi` 명령어 실행 후 메모리를 점유하고 있는 process의 PID를 찾아 `sudo kill -9 {pid}` 로 프로세스 종료해주면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4c676",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1aeec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:29.489879Z",
     "start_time": "2022-10-14T08:27:29.488626Z"
    }
   },
   "outputs": [],
   "source": [
    "## Need to check if packages are compatible\n",
    "# !pip install accelerate nvidia-ml-py3\n",
    "# !pip install datasets==2.4.0\n",
    "# !pip install huggingface_hub==0.9.1\n",
    "# !pip install transformers==4.22.1 # bf16, tf32 등 사용하려면 4.2 이상 필요\n",
    "# !pip install pyarrow==9.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88dd3d8",
   "metadata": {},
   "source": [
    "* huggingface_hub와 transformers 간 호환가능한 버전 확인 필요\n",
    "* 만약 성능 테스트를 위해 datasets api를 사용할거라면 datasets 역시 호환 가능 버전 확인해야 함\n",
    "* 세 가지 dependencies를 사용한다는 가정 하에, pyarrow 라이브러리도 필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50efac54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:30.102997Z",
     "start_time": "2022-10-14T08:27:29.490516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.22.1\n",
      "2.4.0\n",
      "0.9.1\n",
      "9.0.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import huggingface_hub\n",
    "import pyarrow\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)\n",
    "print(huggingface_hub.__version__)\n",
    "print(pyarrow.__version__)\n",
    "\n",
    "# 4.22.1\n",
    "# 2.4.0\n",
    "# 0.9.1\n",
    "# 9.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4db4071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:31.308189Z",
     "start_time": "2022-10-14T08:27:30.103688Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 'You can use tf32' if you are acessing Ampere hardware\n",
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from datasets import load_dataset, load_metric, ClassLabel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.examples.pbt_transformers.utils import (\n",
    "    download_data,\n",
    "    build_compute_metrics_fn,\n",
    ")\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from transformers import (\n",
    "    glue_tasks_num_labels,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    GlueDataset,\n",
    "    GlueDataTrainingArguments,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "440c7201",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:12:40.333836Z",
     "start_time": "2022-10-14T09:12:40.327479Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3f454",
   "metadata": {},
   "source": [
    "# 2. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b3349",
   "metadata": {},
   "source": [
    "* xxx_train.csv, xxx_test.csv 파일은 아래 형식으로 전처리된 csv 파일이어야 함 (column name: `text`, `label`)\n",
    "\n",
    "\n",
    "<table class=\"features-table\">\n",
    "  <tr>\n",
    "    <th class=\"mdc-text-light-green-600\", style=\"text-align:center\">\n",
    "    text\n",
    "    </th>\n",
    "    <th class=\"mdc-text-purple-600\", style=\"text-align:center\">\n",
    "    label\n",
    "    </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      Ok lar... Joking wif u oni...\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      1\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      U dun say so early hor... U c already then say...\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      Nah I don't think he goes to usf, he lives around here though\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6e81be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:32.902693Z",
     "start_time": "2022-10-14T08:27:31.537472Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5e9b2acfce9f0b59\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-5e9b2acfce9f0b59/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bbf659f3ae433681edcf9a73e7b214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 39999\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 9999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = \"IMDB\" ## covid_articles / financial_news / IMDB / naver_movie_review / spam\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train': f'../data_splited/{data_name}_train.csv',\n",
    "                                          'test': f'../data_splited/{data_name}_test.csv'})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d565c1",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing\n",
    "\n",
    "* load_dataset 함수로 불러온 데이터를 수정할 때는 수정 내용을 담은 함수를 만들고, 이를 map 함수로 각 원소에 적용함 ([링크](https://huggingface.co/docs/datasets/v1.4.0/processing.html#processing-data-row-by-row)에서 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86f9f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:32.925362Z",
     "start_time": "2022-10-14T08:27:32.903338Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5e9b2acfce9f0b59/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-0c659aeae188f731.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5e9b2acfce9f0b59/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-170d6a353647063a.arrow\n"
     ]
    }
   ],
   "source": [
    "## remove specal characters\n",
    "\n",
    "def remove_sp(example):\n",
    "    example[\"text\"]=re.sub(r'[^a-z|A-Z|0-9|ㄱ-ㅎ|ㅏ-ㅣ|가-힣| ]+', '', str(example[\"text\"]))\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(remove_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "376b792e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:32.968675Z",
     "start_time": "2022-10-14T08:27:32.926077Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5e9b2acfce9f0b59/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-82b60351b1fd1890.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5e9b2acfce9f0b59/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-0fbc2fb5dafc34c1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "## label encoding\n",
    "\n",
    "labels = list(set(dataset[\"train\"][\"label\"] + dataset[\"test\"][\"label\"]))\n",
    "num_labels = len(labels)\n",
    "\n",
    "def encoding_label(example):\n",
    "    str_to_int = ClassLabel(num_classes=num_labels, names=labels)\n",
    "    example[\"label\"]=str_to_int.str2int(example[\"label\"])\n",
    "    return example\n",
    "\n",
    "if type(labels[0]) == str:\n",
    "    dataset = dataset.map(encoding_label)\n",
    "    \n",
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf98414",
   "metadata": {},
   "source": [
    "# 4. Load PLM & Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "120ed80f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:32.970442Z",
     "start_time": "2022-10-14T08:27:32.969280Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "# model_name = \"bert-base-multilingual-cased\"\n",
    "# model_name = \"xlm-roberta-base\"\n",
    "\n",
    "# model_name = \"klue/bert-base\"\n",
    "# model_name = \"klue/roberta-base\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b76b56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:34.326180Z",
     "start_time": "2022-10-14T08:27:32.971010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download cache tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ac27d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:34.328707Z",
     "start_time": "2022-10-14T08:27:34.326958Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    tokenized_batch = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True) # padding : ['longest', 'max_length', 'do_not_pad']\n",
    "    return tokenized_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12cd882e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:38.297098Z",
     "start_time": "2022-10-14T08:27:34.329307Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5e9b2acfce9f0b59/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-1b3db1ac7e2ce261.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19676f7e9544a2389fe2eb093b3a192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff424b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:38.299345Z",
     "start_time": "2022-10-14T08:27:38.297896Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dataset = tokenized_datasets[\"train\"].shuffle(seed=1919).select(range(0,math.floor(len(tokenized_datasets[\"train\"])*0.7)))\n",
    "# eval_dataset = tokenized_datasets[\"train\"].shuffle(seed=1919).select(range(math.floor(len(tokenized_datasets[\"train\"])*0.7), len(tokenized_datasets[\"train\"])))\n",
    "# test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd2e26d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:38.318522Z",
     "start_time": "2022-10-14T08:27:38.299940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-5e9b2acfce9f0b59/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-e9e4b6fdb429ddad.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-5e9b2acfce9f0b59/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-e9e4b6fdb429ddad.arrow\n"
     ]
    }
   ],
   "source": [
    "# data for test\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=1919).select(range(1000))\n",
    "eval_dataset = tokenized_datasets[\"train\"].shuffle(seed=1919).select(range(1000))\n",
    "test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849bd50",
   "metadata": {},
   "source": [
    "# 5. Check class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a7ca12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:38.321145Z",
     "start_time": "2022-10-14T08:27:38.319141Z"
    }
   },
   "outputs": [],
   "source": [
    "def class_weight(train_dataset) :\n",
    "    \n",
    "    train_labels = np.array(train_dataset[\"label\"])\n",
    "    class_weights = compute_class_weight(class_weight = 'balanced', classes = np.unique(train_labels), y = train_labels)\n",
    "    \n",
    "    weights = torch.tensor(class_weights, dtype = torch.float)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b03360fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T08:27:38.368152Z",
     "start_time": "2022-10-14T08:27:38.321715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0225, 0.9785])\n"
     ]
    }
   ],
   "source": [
    "weights = class_weight(train_dataset)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82504529",
   "metadata": {},
   "source": [
    "# 6. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68953af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:11:57.756504Z",
     "start_time": "2022-10-14T09:11:55.844766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be993fad56c24b52826701e936bf0545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Customize training strategy\n",
    "\n",
    "task_data_dir = \"test-model\"\n",
    "gpus_per_trial = 1\n",
    "cpus_per_trial = 16\n",
    "n_trials = 5\n",
    "metric = load_metric(\"f1\") # atasets.list_metrics() \n",
    "seed = 818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc537bd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:11:58.626508Z",
     "start_time": "2022-10-14T09:11:57.761187Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download model and features\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        config=config\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28224d39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:11:58.637089Z",
     "start_time": "2022-10-14T09:11:58.629108Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions=np.argmax(logits, axis = -1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf019a",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=1,              # total number of training epochs\n",
    "    per_device_train_batch_size=1,   # batch size per device during training\n",
    "    per_device_eval_batch_size=10,   # batch size for evaluation\n",
    "    warmup_steps=1000,               # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=200,               # How often to print logs\n",
    "    do_train=True,                   # Perform training\n",
    "    do_eval=True,                    # Perform evaluation\n",
    "    evaluation_strategy=\"epoch\",     # evalute after each epoch\n",
    "    gradient_accumulation_steps=64,  # total number of steps before back propagation\n",
    "    fp16=True,                       # Use mixed precision\n",
    "    fp16_opt_level=\"02\",             # mixed precision mode\n",
    "    run_name=\"ProBert-BFD-MS\",       # experiment name\n",
    "    seed=3                           # Seed for experiment reproducibility 3x3\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83d10216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:12:48.077267Z",
     "start_time": "2022-10-14T09:12:45.315670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\".\",\n",
    "    learning_rate=2e-5, # config\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    no_cuda=gpus_per_trial <= 0,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=2,  # config\n",
    "    max_steps=-1,  # config\n",
    "    per_device_train_batch_size=8,  # config\n",
    "    per_device_eval_batch_size=8,  # config\n",
    "    warmup_steps=0,\n",
    "    warmup_ratio=0.1,  # config\n",
    "    weight_decay=0.1,  # config\n",
    "    logging_dir=\"./logs\",\n",
    "    skip_memory_metrics=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    # bf16=True,\n",
    "    # tf32=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    seed=seed,\n",
    "    eval_steps = 50\n",
    "    )\n",
    "    \n",
    "# trainer = Trainer(\n",
    "#     model_init=model_init,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     )\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss\n",
    "        weight = weights.to(device)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "trainer = CustomTrainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85a527",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-14T09:15:37.514Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2901398)\u001b[0m 2022-10-14 09:15:39.436636: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:15:37 (running for 00:00:00.28)\n",
      "Memory usage on this node: 11.4/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (4 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_c4104_00000 | RUNNING  | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |\n",
      "| _objective_c4104_00001 | PENDING  |                    | 0.215004  | 1.48101e-05 |                |            5 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m /opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m   warnings.warn(\n",
      "  0%|          | 0/62 [00:00<?, ?it/s]\n",
      "  2%|▏         | 1/62 [00:00<00:40,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:15:45 (running for 00:00:07.93)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (4 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_c4104_00000 | RUNNING  | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |\n",
      "| _objective_c4104_00001 | PENDING  |                    | 0.215004  | 1.48101e-05 |                |            5 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/62 [00:01<00:38,  1.54it/s]\n",
      "  5%|▍         | 3/62 [00:01<00:38,  1.55it/s]\n",
      "  6%|▋         | 4/62 [00:02<00:37,  1.55it/s]\n",
      "  8%|▊         | 5/62 [00:03<00:36,  1.56it/s]\n",
      " 10%|▉         | 6/62 [00:03<00:35,  1.56it/s]\n",
      " 11%|█▏        | 7/62 [00:04<00:35,  1.56it/s]\n",
      " 13%|█▎        | 8/62 [00:05<00:34,  1.56it/s]\n",
      " 15%|█▍        | 9/62 [00:05<00:33,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:15:50 (running for 00:00:12.93)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (4 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_c4104_00000 | RUNNING  | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |\n",
      "| _objective_c4104_00001 | PENDING  |                    | 0.215004  | 1.48101e-05 |                |            5 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 10/62 [00:06<00:33,  1.56it/s]\n",
      " 18%|█▊        | 11/62 [00:07<00:32,  1.56it/s]\n",
      " 19%|█▉        | 12/62 [00:08<00:36,  1.36it/s]\n",
      " 21%|██        | 13/62 [00:08<00:34,  1.41it/s]\n",
      " 23%|██▎       | 14/62 [00:09<00:32,  1.45it/s]\n",
      " 24%|██▍       | 15/62 [00:09<00:31,  1.48it/s]\n",
      " 26%|██▌       | 16/62 [00:10<00:30,  1.51it/s]\n",
      " 27%|██▋       | 17/62 [00:11<00:29,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:15:55 (running for 00:00:17.94)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (4 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_c4104_00000 | RUNNING  | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |\n",
      "| _objective_c4104_00001 | PENDING  |                    | 0.215004  | 1.48101e-05 |                |            5 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 18/62 [00:11<00:28,  1.53it/s]\n",
      " 31%|███       | 19/62 [00:12<00:27,  1.54it/s]\n",
      " 32%|███▏      | 20/62 [00:13<00:27,  1.55it/s]\n",
      " 34%|███▍      | 21/62 [00:13<00:26,  1.55it/s]\n",
      " 35%|███▌      | 22/62 [00:14<00:25,  1.55it/s]\n",
      " 37%|███▋      | 23/62 [00:15<00:25,  1.55it/s]\n",
      " 39%|███▊      | 24/62 [00:15<00:24,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:00 (running for 00:00:22.94)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (4 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_c4104_00000 | RUNNING  | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |\n",
      "| _objective_c4104_00001 | PENDING  |                    | 0.215004  | 1.48101e-05 |                |            5 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 25/62 [00:16<00:23,  1.55it/s]\n",
      " 42%|████▏     | 26/62 [00:17<00:23,  1.56it/s]\n",
      " 44%|████▎     | 27/62 [00:17<00:22,  1.56it/s]\n",
      " 45%|████▌     | 28/62 [00:18<00:21,  1.56it/s]\n",
      " 47%|████▋     | 29/62 [00:18<00:21,  1.56it/s]\n",
      " 48%|████▊     | 30/62 [00:19<00:20,  1.56it/s]\n",
      " 50%|█████     | 31/62 [00:20<00:19,  1.56it/s]\n",
      " 52%|█████▏    | 32/62 [00:21<00:20,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:05 (running for 00:00:27.94)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (4 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_c4104_00000 | RUNNING  | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |\n",
      "| _objective_c4104_00001 | PENDING  |                    | 0.215004  | 1.48101e-05 |                |            5 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 33/62 [00:21<00:19,  1.48it/s]\n",
      " 55%|█████▍    | 34/62 [00:22<00:18,  1.50it/s]\n",
      " 56%|█████▋    | 35/62 [00:22<00:17,  1.52it/s]\n",
      " 58%|█████▊    | 36/62 [00:23<00:16,  1.53it/s]\n",
      " 60%|█████▉    | 37/62 [00:24<00:16,  1.54it/s]\n",
      " 61%|██████▏   | 38/62 [00:24<00:15,  1.54it/s]\n",
      " 63%|██████▎   | 39/62 [00:25<00:14,  1.55it/s]\n",
      " 65%|██████▍   | 40/62 [00:26<00:14,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:10 (running for 00:00:32.94)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (4 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_c4104_00000 | RUNNING  | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |\n",
      "| _objective_c4104_00001 | PENDING  |                    | 0.215004  | 1.48101e-05 |                |            5 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 41/62 [00:26<00:13,  1.55it/s]\n",
      " 68%|██████▊   | 42/62 [00:27<00:12,  1.56it/s]\n",
      " 69%|██████▉   | 43/62 [00:28<00:12,  1.56it/s]\n",
      " 71%|███████   | 44/62 [00:28<00:11,  1.56it/s]\n",
      " 73%|███████▎  | 45/62 [00:29<00:10,  1.56it/s]\n",
      " 74%|███████▍  | 46/62 [00:29<00:10,  1.56it/s]\n",
      " 76%|███████▌  | 47/62 [00:30<00:09,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:15 (running for 00:00:37.94)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (4 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_c4104_00000 | RUNNING  | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |\n",
      "| _objective_c4104_00001 | PENDING  |                    | 0.215004  | 1.48101e-05 |                |            5 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 48/62 [00:31<00:08,  1.56it/s]\n",
      " 79%|███████▉  | 49/62 [00:31<00:08,  1.56it/s]\n",
      " 81%|████████  | 50/62 [00:32<00:07,  1.56it/s]\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      "  3%|▎         | 4/125 [00:00<00:03, 32.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      "  6%|▋         | 8/125 [00:00<00:04, 26.87it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      "  9%|▉         | 11/125 [00:00<00:04, 25.78it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 11%|█         | 14/125 [00:00<00:04, 25.14it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 14%|█▎        | 17/125 [00:00<00:04, 24.79it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 16%|█▌        | 20/125 [00:00<00:04, 24.57it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 18%|█▊        | 23/125 [00:00<00:04, 24.42it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 21%|██        | 26/125 [00:01<00:04, 24.34it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 23%|██▎       | 29/125 [00:01<00:03, 24.27it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 26%|██▌       | 32/125 [00:01<00:03, 24.17it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 28%|██▊       | 35/125 [00:01<00:03, 24.16it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 30%|███       | 38/125 [00:01<00:03, 24.14it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 33%|███▎      | 41/125 [00:01<00:03, 24.08it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 35%|███▌      | 44/125 [00:01<00:03, 24.09it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 38%|███▊      | 47/125 [00:01<00:03, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 40%|████      | 50/125 [00:02<00:03, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 42%|████▏     | 53/125 [00:02<00:02, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 45%|████▍     | 56/125 [00:02<00:02, 24.10it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 47%|████▋     | 59/125 [00:02<00:02, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 50%|████▉     | 62/125 [00:02<00:02, 24.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 52%|█████▏    | 65/125 [00:02<00:02, 24.08it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 54%|█████▍    | 68/125 [00:02<00:02, 24.09it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 57%|█████▋    | 71/125 [00:02<00:02, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 59%|█████▉    | 74/125 [00:03<00:02, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 62%|██████▏   | 77/125 [00:03<00:01, 24.09it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 64%|██████▍   | 80/125 [00:03<00:01, 24.10it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 66%|██████▋   | 83/125 [00:03<00:01, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 69%|██████▉   | 86/125 [00:03<00:01, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 71%|███████   | 89/125 [00:03<00:01, 24.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:20 (running for 00:00:42.95)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (4 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_c4104_00000 | RUNNING  | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |\n",
      "| _objective_c4104_00001 | PENDING  |                    | 0.215004  | 1.48101e-05 |                |            5 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 74%|███████▎  | 92/125 [00:03<00:01, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 76%|███████▌  | 95/125 [00:03<00:01, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 78%|███████▊  | 98/125 [00:04<00:01, 24.12it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 81%|████████  | 101/125 [00:04<00:00, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 83%|████████▎ | 104/125 [00:04<00:00, 24.06it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 86%|████████▌ | 107/125 [00:04<00:00, 24.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 88%|████████▊ | 110/125 [00:04<00:00, 24.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 90%|█████████ | 113/125 [00:04<00:00, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 93%|█████████▎| 116/125 [00:04<00:00, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 95%|█████████▌| 119/125 [00:04<00:00, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      " 98%|█████████▊| 122/125 [00:05<00:00, 13.53it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      "                                               s]\u001b[A\n",
      " 81%|████████  | 50/62 [00:38<00:07,  1.56it/s]  \n",
      "100%|██████████| 125/125 [00:05<00:00, 15.58it/s]\u001b[Aearly stopping required metric_for_best_model, but did not find eval_accuracy so early stopping is disabled\n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m \n",
      "                                                 \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_c4104_00000:\n",
      "  date: 2022-10-14_09-16-22\n",
      "  done: false\n",
      "  epoch: 1.61\n",
      "  eval_f1: 0.8470588235294118\n",
      "  eval_loss: 0.5500108599662781\n",
      "  eval_runtime: 5.5226\n",
      "  eval_samples_per_second: 181.074\n",
      "  eval_steps_per_second: 22.634\n",
      "  experiment_id: 4b9631f24c0149ed85033ea5d5f57577\n",
      "  hostname: 3481a8a2ae33\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.3\n",
      "  objective: 0.8470588235294118\n",
      "  pid: 2901398\n",
      "  time_since_restore: 41.78634071350098\n",
      "  time_this_iter_s: 41.78634071350098\n",
      "  time_total_s: 41.78634071350098\n",
      "  timestamp: 1665738982\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c4104_00000\n",
      "  warmup_time: 0.0027446746826171875\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=2901398)\u001b[0m {'eval_loss': 0.5500108599662781, 'eval_f1': 0.8470588235294118, 'eval_runtime': 5.5226, 'eval_samples_per_second': 181.074, 'eval_steps_per_second': 22.634, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 50/62 [00:38<00:09,  1.31it/s]\n",
      "\u001b[2m\u001b[36m(pid=2901654)\u001b[0m 2022-10-14 09:16:24.114137: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:27 (running for 00:00:50.36)\n",
      "Memory usage on this node: 15.3/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (1 PAUSED, 3 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |   eval_f1 |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------|\n",
      "| _objective_c4104_00001 | RUNNING  | 172.17.0.3:2901654 | 0.215004  | 1.48101e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00000 | PAUSED   | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |  0.847059 |    0.550011 |    1.61 |                    1 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |           |             |         |                      |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |           |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m /opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m   warnings.warn(\n",
      "  0%|          | 0/155 [00:00<?, ?it/s]\n",
      "  1%|          | 1/155 [00:00<01:41,  1.52it/s]\n",
      "  1%|▏         | 2/155 [00:01<01:39,  1.54it/s]\n",
      "  2%|▏         | 3/155 [00:01<01:37,  1.55it/s]\n",
      "  3%|▎         | 4/155 [00:02<01:37,  1.55it/s]\n",
      "  3%|▎         | 5/155 [00:03<01:36,  1.56it/s]\n",
      "  4%|▍         | 6/155 [00:03<01:35,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:32 (running for 00:00:55.37)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (1 PAUSED, 3 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |   eval_f1 |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------|\n",
      "| _objective_c4104_00001 | RUNNING  | 172.17.0.3:2901654 | 0.215004  | 1.48101e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00000 | PAUSED   | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |  0.847059 |    0.550011 |    1.61 |                    1 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |           |             |         |                      |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |           |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 7/155 [00:04<01:35,  1.56it/s]\n",
      "  5%|▌         | 8/155 [00:05<01:34,  1.56it/s]\n",
      "  6%|▌         | 9/155 [00:05<01:33,  1.56it/s]\n",
      "  6%|▋         | 10/155 [00:06<01:33,  1.56it/s]\n",
      "  7%|▋         | 11/155 [00:07<01:32,  1.56it/s]\n",
      "  8%|▊         | 12/155 [00:07<01:31,  1.56it/s]\n",
      "  8%|▊         | 13/155 [00:08<01:31,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:37 (running for 00:01:00.37)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (1 PAUSED, 3 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |   eval_f1 |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------|\n",
      "| _objective_c4104_00001 | RUNNING  | 172.17.0.3:2901654 | 0.215004  | 1.48101e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00000 | PAUSED   | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |  0.847059 |    0.550011 |    1.61 |                    1 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |           |             |         |                      |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |           |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/155 [00:09<01:30,  1.56it/s]\n",
      " 10%|▉         | 15/155 [00:09<01:29,  1.56it/s]\n",
      " 10%|█         | 16/155 [00:10<01:29,  1.55it/s]\n",
      " 11%|█         | 17/155 [00:10<01:28,  1.56it/s]\n",
      " 12%|█▏        | 18/155 [00:11<01:28,  1.56it/s]\n",
      " 12%|█▏        | 19/155 [00:12<01:27,  1.56it/s]\n",
      " 13%|█▎        | 20/155 [00:12<01:26,  1.56it/s]\n",
      " 14%|█▎        | 21/155 [00:13<01:26,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:42 (running for 00:01:05.37)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (1 PAUSED, 3 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |   eval_f1 |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------|\n",
      "| _objective_c4104_00001 | RUNNING  | 172.17.0.3:2901654 | 0.215004  | 1.48101e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00000 | PAUSED   | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |  0.847059 |    0.550011 |    1.61 |                    1 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |           |             |         |                      |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |           |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 22/155 [00:14<01:25,  1.56it/s]\n",
      " 15%|█▍        | 23/155 [00:14<01:24,  1.56it/s]\n",
      " 15%|█▌        | 24/155 [00:15<01:24,  1.56it/s]\n",
      " 16%|█▌        | 25/155 [00:16<01:23,  1.56it/s]\n",
      " 17%|█▋        | 26/155 [00:16<01:22,  1.56it/s]\n",
      " 17%|█▋        | 27/155 [00:17<01:22,  1.56it/s]\n",
      " 18%|█▊        | 28/155 [00:17<01:21,  1.56it/s]\n",
      " 19%|█▊        | 29/155 [00:18<01:20,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:47 (running for 00:01:10.37)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (1 PAUSED, 3 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |   eval_f1 |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------|\n",
      "| _objective_c4104_00001 | RUNNING  | 172.17.0.3:2901654 | 0.215004  | 1.48101e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00000 | PAUSED   | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |  0.847059 |    0.550011 |    1.61 |                    1 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |           |             |         |                      |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |           |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 30/155 [00:19<01:20,  1.56it/s]\n",
      " 20%|██        | 31/155 [00:19<01:19,  1.56it/s]\n",
      " 21%|██        | 32/155 [00:20<01:24,  1.45it/s]\n",
      " 21%|██▏       | 33/155 [00:21<01:22,  1.48it/s]\n",
      " 22%|██▏       | 34/155 [00:22<01:20,  1.50it/s]\n",
      " 23%|██▎       | 35/155 [00:22<01:19,  1.52it/s]\n",
      " 23%|██▎       | 36/155 [00:23<01:29,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:52 (running for 00:01:15.47)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (1 PAUSED, 3 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |   eval_f1 |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------|\n",
      "| _objective_c4104_00001 | RUNNING  | 172.17.0.3:2901654 | 0.215004  | 1.48101e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00000 | PAUSED   | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |  0.847059 |    0.550011 |    1.61 |                    1 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |           |             |         |                      |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |           |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 37/155 [00:24<01:24,  1.39it/s]\n",
      " 25%|██▍       | 38/155 [00:24<01:21,  1.44it/s]\n",
      " 25%|██▌       | 39/155 [00:25<01:18,  1.47it/s]\n",
      " 26%|██▌       | 40/155 [00:26<01:16,  1.50it/s]\n",
      " 26%|██▋       | 41/155 [00:26<01:15,  1.51it/s]\n",
      " 27%|██▋       | 42/155 [00:27<01:14,  1.53it/s]\n",
      " 28%|██▊       | 43/155 [00:28<01:12,  1.54it/s]\n",
      " 28%|██▊       | 44/155 [00:28<01:11,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:16:57 (running for 00:01:20.47)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (1 PAUSED, 3 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |   eval_f1 |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------|\n",
      "| _objective_c4104_00001 | RUNNING  | 172.17.0.3:2901654 | 0.215004  | 1.48101e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00000 | PAUSED   | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |  0.847059 |    0.550011 |    1.61 |                    1 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |           |             |         |                      |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |           |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 45/155 [00:29<01:11,  1.55it/s]\n",
      " 30%|██▉       | 46/155 [00:30<01:10,  1.55it/s]\n",
      " 30%|███       | 47/155 [00:30<01:09,  1.55it/s]\n",
      " 31%|███       | 48/155 [00:31<01:09,  1.55it/s]\n",
      " 32%|███▏      | 49/155 [00:31<01:08,  1.55it/s]\n",
      " 32%|███▏      | 50/155 [00:32<01:07,  1.55it/s]\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      "  3%|▎         | 4/125 [00:00<00:03, 32.16it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      "  6%|▋         | 8/125 [00:00<00:04, 26.84it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      "  9%|▉         | 11/125 [00:00<00:04, 25.72it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 11%|█         | 14/125 [00:00<00:04, 25.10it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 14%|█▎        | 17/125 [00:00<00:04, 24.75it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 16%|█▌        | 20/125 [00:00<00:04, 24.52it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 18%|█▊        | 23/125 [00:00<00:04, 24.39it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 21%|██        | 26/125 [00:01<00:04, 24.31it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 23%|██▎       | 29/125 [00:01<00:03, 24.24it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 26%|██▌       | 32/125 [00:01<00:03, 24.21it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 28%|██▊       | 35/125 [00:01<00:03, 24.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-14 09:17:02 (running for 00:01:25.47)\n",
      "Memory usage on this node: 15.7/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/20 CPUs, 1.0/1 GPUs, 0.0/15.25 GiB heap, 0.0/7.62 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 5/5 (1 PAUSED, 3 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr | train_bs/gpu   |   num_epochs |   eval_f1 |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------|\n",
      "| _objective_c4104_00001 | RUNNING  | 172.17.0.3:2901654 | 0.215004  | 1.48101e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00000 | PAUSED   | 172.17.0.3:2901398 | 0.0885716 | 4.40175e-05 |                |            2 |  0.847059 |    0.550011 |    1.61 |                    1 |\n",
      "| _objective_c4104_00002 | PENDING  |                    | 0.209523  | 1.513e-05   |                |           10 |           |             |         |                      |\n",
      "| _objective_c4104_00003 | PENDING  |                    | 0.119507  | 4.51004e-05 |                |            5 |           |             |         |                      |\n",
      "| _objective_c4104_00004 | PENDING  |                    | 0.244833  | 2.68554e-05 |                |            5 |           |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 30%|███       | 38/125 [00:01<00:03, 24.16it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 33%|███▎      | 41/125 [00:01<00:03, 24.12it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 35%|███▌      | 44/125 [00:01<00:03, 24.12it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 38%|███▊      | 47/125 [00:01<00:03, 24.10it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 40%|████      | 50/125 [00:02<00:03, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 42%|████▏     | 53/125 [00:02<00:02, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 45%|████▍     | 56/125 [00:02<00:02, 24.10it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 47%|████▋     | 59/125 [00:02<00:02, 24.06it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 50%|████▉     | 62/125 [00:02<00:02, 24.06it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 52%|█████▏    | 65/125 [00:02<00:02, 24.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 54%|█████▍    | 68/125 [00:02<00:02, 24.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 57%|█████▋    | 71/125 [00:02<00:02, 24.06it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 59%|█████▉    | 74/125 [00:03<00:02, 24.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 62%|██████▏   | 77/125 [00:03<00:01, 24.08it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 64%|██████▍   | 80/125 [00:03<00:01, 24.09it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 66%|██████▋   | 83/125 [00:03<00:01, 24.06it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 69%|██████▉   | 86/125 [00:03<00:01, 24.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 71%|███████   | 89/125 [00:03<00:01, 24.10it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 74%|███████▎  | 92/125 [00:03<00:01, 24.11it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 76%|███████▌  | 95/125 [00:03<00:01, 24.07it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 78%|███████▊  | 98/125 [00:04<00:01, 24.05it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 81%|████████  | 101/125 [00:04<00:00, 24.05it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 83%|████████▎ | 104/125 [00:04<00:00, 24.06it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 86%|████████▌ | 107/125 [00:04<00:00, 24.05it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 88%|████████▊ | 110/125 [00:04<00:00, 24.05it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 90%|█████████ | 113/125 [00:04<00:00, 24.05it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 93%|█████████▎| 116/125 [00:04<00:00, 23.81it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 95%|█████████▌| 119/125 [00:04<00:00, 23.89it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      " 98%|█████████▊| 122/125 [00:05<00:00, 23.80it/s]\u001b[A\n",
      "2022-10-14 09:17:06,625\tINFO pbt.py:552 -- [pbt]: no checkpoint for trial. Skip exploit for Trial _objective_c4104_00001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_c4104_00001:\n",
      "  date: 2022-10-14_09-17-06\n",
      "  done: false\n",
      "  epoch: 1.61\n",
      "  eval_f1: 0.7258771929824562\n",
      "  eval_loss: 0.5450262427330017\n",
      "  eval_runtime: 5.2179\n",
      "  eval_samples_per_second: 191.649\n",
      "  eval_steps_per_second: 23.956\n",
      "  experiment_id: a6f8c91886154a9681070e0400ff5285\n",
      "  hostname: 3481a8a2ae33\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.3\n",
      "  objective: 0.7258771929824562\n",
      "  pid: 2901654\n",
      "  time_since_restore: 41.554603576660156\n",
      "  time_this_iter_s: 41.554603576660156\n",
      "  time_total_s: 41.554603576660156\n",
      "  timestamp: 1665739026\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c4104_00001\n",
      "  warmup_time: 0.0019211769104003906\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m {'eval_loss': 0.5450262427330017, 'eval_f1': 0.7258771929824562, 'eval_runtime': 5.2179, 'eval_samples_per_second': 191.649, 'eval_steps_per_second': 23.956, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \r",
      "100%|██████████| 125/125 [00:05<00:00, 23.42it/s]\u001b[A\r",
      "                                                \n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \r",
      "                                                 \r",
      "\u001b[A\r",
      " 32%|███▏      | 50/155 [00:37<01:07,  1.55it/s]\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \r",
      "100%|██████████| 125/125 [00:05<00:00, 23.42it/s]\u001b[Aearly stopping required metric_for_best_model, but did not find eval_accuracy so early stopping is disabled\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \r",
      "                                                 \u001b[A\n",
      "\u001b[2m\u001b[36m(_objective pid=2901654)\u001b[0m \r",
      " 32%|███▏      | 50/155 [00:37<01:19,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with ray tune\n",
    "\n",
    "tune_config = {\n",
    "#     \"per_device_train_batch_size\": tune.choice([2, 4, 8]),\n",
    "    \"num_train_epochs\": tune.choice([2, 5, 10]),\n",
    "#     \"num_train_epochs\": [x for x in range(2, 21)],\n",
    "}\n",
    "\n",
    "# PopulationBasedTraining\n",
    "# worker might copy the model parameters from a better performing worker or explore new hyperparameters by changing the current values randomly\n",
    "# cf. ASHAScheduler\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=\"eval_f1\",\n",
    "    mode=\"max\",\n",
    "    perturbation_interval=1,\n",
    "    hyperparam_mutations={\n",
    "#         \"num_train_epochs\": [x for x in range(2, 21)],\n",
    "        \"weight_decay\": tune.uniform(0.0, 0.3), # tune.uniform(1, 10) == np.random.uniform(1, 10)\n",
    "        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
    "        \"warmup_ratio\": tune.uniform(0.0, 0.3),\n",
    "#         # Perturb factor3 by changing it to an adjacent value, e.g.\n",
    "#         # 10 -> 1 or 10 -> 100. Resampling will choose at random.\n",
    "#         \"factor_3\": [1, 10, 100, 1000, 10000],\n",
    "#         # Using tune.choice is NOT equivalent to the above.\n",
    "#         # factor_4 is treated as a continuous hyperparameter.\n",
    "#         \"factor_4\": tune.choice([1, 10, 100, 1000, 10000]),\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns={\n",
    "        \"weight_decay\": \"w_decay\",\n",
    "        \"learning_rate\": \"lr\",\n",
    "        \"per_device_train_batch_size\": \"train_bs/gpu\",\n",
    "        \"num_train_epochs\": \"num_epochs\",\n",
    "    },\n",
    "    metric_columns=[\"eval_f1\", \"eval_loss\", \"epoch\", \"training_iteration\"],\n",
    ")\n",
    "\n",
    "result = trainer.hyperparameter_search(\n",
    "    direction = \"maximize\",\n",
    "    hp_space = lambda _: tune_config,\n",
    "    backend=\"ray\",\n",
    "    n_trials=n_trials,\n",
    "    resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n",
    "    scheduler=scheduler,\n",
    "    keep_checkpoints_num=1,\n",
    "    checkpoint_score_attr=\"training_iteration\",\n",
    "    stop=None,\n",
    "    progress_reporter=reporter,\n",
    "    local_dir=\"./test-results\",\n",
    "    name=\"tune_transformer_pbt\",\n",
    "    log_to_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9aea0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:13:35.706014Z",
     "start_time": "2022-10-14T09:12:59.240Z"
    }
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80dbe63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:13:35.706440Z",
     "start_time": "2022-10-14T09:12:59.377Z"
    }
   },
   "outputs": [],
   "source": [
    "for n, v in result.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26870031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:13:35.706775Z",
     "start_time": "2022-10-14T09:12:59.513Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fd2c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:13:35.707151Z",
     "start_time": "2022-10-14T09:12:59.929Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae1e6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:13:35.707531Z",
     "start_time": "2022-10-14T09:13:00.266Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aecdc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:13:35.707940Z",
     "start_time": "2022-10-14T09:13:00.769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=2900563)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_objective pid=2900563)\u001b[0m \r",
      "100%|██████████| 125/125 [00:05<00:00, 24.21it/s]\u001b[A\r",
      "                                                \n",
      "\u001b[2m\u001b[36m(_objective pid=2900563)\u001b[0m \r",
      "                                                 \r",
      "\u001b[A\r",
      " 32%|███▏      | 50/155 [00:37<01:07,  1.56it/s]\n",
      "\u001b[2m\u001b[36m(_objective pid=2900563)\u001b[0m \r",
      "100%|██████████| 125/125 [00:05<00:00, 24.21it/s]\u001b[Aearly stopping required metric_for_best_model, but did not find eval_accuracy so early stopping is disabled\n",
      "\u001b[2m\u001b[36m(_objective pid=2900563)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_objective pid=2900563)\u001b[0m \r",
      "                                                 \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=2900563)\u001b[0m {'eval_loss': 0.6048755049705505, 'eval_f1': 0.6558891454965358, 'eval_runtime': 5.1791, 'eval_samples_per_second': 193.083, 'eval_steps_per_second': 24.135, 'epoch': 1.61}\n"
     ]
    }
   ],
   "source": [
    "trainer.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9d684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:04:29.376526Z",
     "start_time": "2022-10-14T08:27:30.392Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_path = \"test-model\"\n",
    "# trainer.model.save_pretrained(model_path)\n",
    "# tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3f419",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "https://bo-10000.tistory.com/154  \n",
    "https://huggingface.co/blog/ray-tune  \n",
    "https://docs.ray.io/en/latest/tune/examples/pbt_transformers.html  \n",
    "https://wood-b.github.io/post/a-novices-guide-to-hyperparameter-optimization-at-scale/#schedulers-vs-search-algorithms  \n",
    "https://docs.ray.io/en/latest/tune/api_docs/search_space.html  \n",
    "https://docs.ray.io/en/latest/tune/tutorials/tune-advanced-tutorial.html  \n",
    "https://docs.ray.io/en/latest/tune/api_docs/schedulers.html  \n",
    "https://blog.ml.cmu.edu/2018/12/12/massively-parallel-hyperparameter-optimization/  \n",
    "https://docs.ray.io/en/latest/tune/faq.html  \n",
    "https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#population-based-training-tune-schedulers-populationbasedtraining  \n",
    "https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.hyperparameter_search  \n",
    "https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#optuna-tune-search-optuna-optunasearch  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
