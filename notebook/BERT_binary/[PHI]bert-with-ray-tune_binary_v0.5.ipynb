{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3760f4",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "- Host OS: Ubuntu 20.04 lts\n",
    "- Using Docker Image 'mltooling/ml-workspace-gpu' (docker pull mltooling/ml-workspace-gpu)\n",
    "- Single Nvidia GPU (RTX 3080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d991b9",
   "metadata": {},
   "source": [
    "# 0. GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7101f6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:20:21.685645Z",
     "start_time": "2022-10-21T08:20:21.677391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_count: 1\n",
      "device 0 capability (8, 6)\n",
      "device 0 name NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(\"device_count: {}\".format(device_count))\n",
    "    for device_num in range(device_count):\n",
    "        print(\"device {} capability {}\".format(\n",
    "            device_num,\n",
    "            torch.cuda.get_device_capability(device_num)))\n",
    "        print(\"device {} name {}\".format(\n",
    "            device_num, \n",
    "            torch.cuda.get_device_name(device_num)))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"no cuda device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4c676",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1aeec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:29.922621Z",
     "start_time": "2022-10-21T08:18:29.921419Z"
    }
   },
   "outputs": [],
   "source": [
    "## Need to check if packages are compatible ##\n",
    "\n",
    "# !pip install accelerate nvidia-ml-py3\n",
    "# !pip install datasets==2.4.0\n",
    "# !pip install huggingface_hub==0.9.1\n",
    "# !pip install transformers==4.22.1 \n",
    "# !pip install pyarrow==9.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50efac54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:30.553816Z",
     "start_time": "2022-10-21T08:18:29.923286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.22.1\n",
      "2.4.0\n",
      "0.9.1\n",
      "9.0.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import huggingface_hub\n",
    "import pyarrow\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)\n",
    "print(huggingface_hub.__version__)\n",
    "print(pyarrow.__version__)\n",
    "\n",
    "# 4.22.1\n",
    "# 2.4.0\n",
    "# 0.9.1\n",
    "# 9.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4db4071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:31.788264Z",
     "start_time": "2022-10-21T08:18:30.554727Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 'You can use tf32' if you are acessing Ampere hardware\n",
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from datasets import load_dataset, load_metric, ClassLabel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.examples.pbt_transformers.utils import (\n",
    "    download_data,\n",
    "    build_compute_metrics_fn,\n",
    ")\n",
    "from ray.tune.schedulers import PopulationBasedTraining, ASHAScheduler\n",
    "from transformers import (\n",
    "    glue_tasks_num_labels,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    GlueDataset,\n",
    "    GlueDataTrainingArguments,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3f454",
   "metadata": {},
   "source": [
    "# 2. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b3349",
   "metadata": {},
   "source": [
    "* Example data of xxx_train.csv, xxx_test.csv\n",
    "\n",
    "\n",
    "<table class=\"features-table\">\n",
    "  <tr>\n",
    "    <th class=\"mdc-text-light-green-600\", style=\"text-align:center\">\n",
    "    text\n",
    "    </th>\n",
    "    <th class=\"mdc-text-purple-600\", style=\"text-align:center\">\n",
    "    label\n",
    "    </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      Ok lar... Joking wif u oni...\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      1\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      U dun say so early hor... U c already then say...\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      Nah I don't think he goes to usf, he lives around here though\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6e81be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:32.636598Z",
     "start_time": "2022-10-21T08:18:31.789095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-30b40e9c9e0e6156\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-30b40e9c9e0e6156/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd96a955da64ebeb160e05a016b2c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = \"phi\" ## IMDB / naver_movie_review / spam\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train': f'../data_splited/{data_name}_train.csv',\n",
    "                                          'test': f'../data_splited/{data_name}_test.csv'})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d565c1",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86f9f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:32.643338Z",
     "start_time": "2022-10-21T08:18:32.637231Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-30b40e9c9e0e6156/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-3a717fb8aa2e2e7a.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-30b40e9c9e0e6156/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-776c2cd46ee7289f.arrow\n"
     ]
    }
   ],
   "source": [
    "## remove specal characters\n",
    "\n",
    "def remove_sp(example):\n",
    "    example[\"text\"]=re.sub(r'[^a-z|A-Z|0-9|ㄱ-ㅎ|ㅏ-ㅣ|가-힣| ]+', '', str(example[\"text\"]))\n",
    "#     example[\"text\"]=re.sub(r'[^0-9|ㄱ-ㅎ|ㅏ-ㅣ|가-힣| ]+', '', str(example[\"text\"])) # For PLM trained by Korean\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(remove_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376b792e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:32.660329Z",
     "start_time": "2022-10-21T08:18:32.644455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## label encoding\n",
    "\n",
    "labels = list(set(dataset[\"train\"][\"label\"] + dataset[\"test\"][\"label\"]))\n",
    "num_labels = len(labels)\n",
    "\n",
    "def encoding_label(example):\n",
    "    str_to_int = ClassLabel(num_classes=num_labels, names=labels)\n",
    "    example[\"label\"]=str_to_int.str2int(example[\"label\"])\n",
    "    return example\n",
    "\n",
    "if type(labels[0]) == str:\n",
    "    dataset = dataset.map(encoding_label)\n",
    "    \n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16aec902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:32.670182Z",
     "start_time": "2022-10-21T08:18:32.661323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make imbalanced data to test model performance (label 0:label 1 = 8:2)\n",
    "# https://discuss.huggingface.co/t/huggingface-datasets-convert-a-dataset-to-pandas-and-then-convert-it-back/14708/3\n",
    "\n",
    "# df_train = pd.DataFrame(dataset['train'])\n",
    "# df_train_0 = df_train[df_train[\"label\"]==0]\n",
    "# df_train_1 = df_train[df_train[\"label\"]==1].sample(frac=1)[0:math.floor(len(df_train[df_train['label']==0])*0.2)]\n",
    "# dataset[\"train\"] = datasets.Dataset.from_pandas(pd.concat([df_train_0,df_train_1]), preserve_index=False)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf98414",
   "metadata": {},
   "source": [
    "# 4. Load PLM & Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60c52a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:32.684442Z",
     "start_time": "2022-10-21T08:18:32.671500Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cpus = 16\n",
    "num_gpus = 1\n",
    "seed = 1234\n",
    "\n",
    "model_name = \"xlm-roberta-base\" # bert-base-multilingual-cased ; klue/roberta-base ; bert-base-cased ...\n",
    "\n",
    "## Customize training strategy\n",
    "\n",
    "task_data_dir = \"test-model\"\n",
    "gpus_per_trial = 1\n",
    "cpus_per_trial = 16\n",
    "n_trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b971cc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:39.386409Z",
     "start_time": "2022-10-21T08:18:32.684993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 08:18:34,870\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.10</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url=None, python_version='3.8.10', ray_version='2.0.0', ray_commit='cba26cc83f6b5b8a2ff166594a65cb74c0ec8740', address_info={'node_ip_address': '172.17.0.3', 'raylet_ip_address': '172.17.0.3', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-10-21_08-18-32_695524_4174489/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-10-21_08-18-32_695524_4174489/sockets/raylet', 'webui_url': None, 'session_dir': '/tmp/ray/session_2022-10-21_08-18-32_695524_4174489', 'metrics_export_port': 58981, 'gcs_address': '172.17.0.3:64317', 'address': '172.17.0.3:64317', 'dashboard_agent_listen_port': 52365, 'node_id': '9fd018e04d171b6aae5341e96bf8d8416b32054a94a51ac9728c7ba2'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ray\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(log_to_driver=False, ignore_reinit_error=True, num_cpus=num_cpus, num_gpus=num_gpus, include_dashboard=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b76b56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:43.055118Z",
     "start_time": "2022-10-21T08:18:39.387307Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-30b40e9c9e0e6156/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-2a6d558e3cdf2f0f.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-30b40e9c9e0e6156/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-e5a8a54d2ba50d34.arrow\n"
     ]
    }
   ],
   "source": [
    "# Download cache tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, truncation_side = 'left') # truncation_side = 'left' option remains last 512 tokens\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenized_batch = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True) # padding : ['longest', 'max_length', 'do_not_pad']\n",
    "    return tokenized_batch\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c7ca87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:43.063219Z",
     "start_time": "2022-10-21T08:18:43.055794Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-30b40e9c9e0e6156/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-94343dfd2a188952.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=seed).select(range(0,math.floor(len(tokenized_datasets[\"train\"])*0.7)))\n",
    "eval_dataset = tokenized_datasets[\"train\"].shuffle(seed=seed).select(range(math.floor(len(tokenized_datasets[\"train\"])*0.7), len(tokenized_datasets[\"train\"])))\n",
    "test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4048b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:43.074799Z",
     "start_time": "2022-10-21T08:18:43.063846Z"
    }
   },
   "outputs": [],
   "source": [
    "## sampling 1000 rows for test\n",
    "\n",
    "# train_dataset = tokenized_datasets[\"train\"].shuffle(seed=seed).select(range(1000))\n",
    "# eval_dataset = tokenized_datasets[\"train\"].shuffle(seed=seed).select(range(1000))\n",
    "# test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849bd50",
   "metadata": {},
   "source": [
    "# 5. Check class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a7ca12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:43.085112Z",
     "start_time": "2022-10-21T08:18:43.075436Z"
    }
   },
   "outputs": [],
   "source": [
    "def class_weight(train_dataset) :\n",
    "    \n",
    "    train_labels = np.array(train_dataset[\"label\"])\n",
    "    class_weights = compute_class_weight(class_weight = 'balanced', classes = np.unique(train_labels), y = train_labels)\n",
    "    \n",
    "    weights = torch.tensor(class_weights, dtype = torch.float)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b03360fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:43.106500Z",
     "start_time": "2022-10-21T08:18:43.086177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6335, 2.3729])\n"
     ]
    }
   ],
   "source": [
    "weights = class_weight(train_dataset)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82504529",
   "metadata": {},
   "source": [
    "# 6. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc537bd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:43.111739Z",
     "start_time": "2022-10-21T08:18:43.107863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download model and features\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28224d39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:43.122438Z",
     "start_time": "2022-10-21T08:18:43.113044Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"glue\", \"mrpc\") # Accuracy/F1\n",
    "#     metric = load_metric(\"accuracy\") # Accuracy/F1\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83d10216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:18:47.477860Z",
     "start_time": "2022-10-21T08:18:43.124270Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/pytorch_model.bin\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\".\",\n",
    "    learning_rate=2e-5, # config\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    no_cuda=gpus_per_trial <= 0,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps = 50,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=2,  # config\n",
    "    max_steps=-1,\n",
    "    per_device_train_batch_size=8,  # config\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=0,\n",
    "    warmup_ratio=0.1,  # config\n",
    "    weight_decay=0.1,  # config\n",
    "    logging_dir=\"./logs\",\n",
    "    skip_memory_metrics=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    seed=seed  # config\n",
    "    )\n",
    "    \n",
    "# trainer = Trainer(\n",
    "#     model_init=model_init,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     )\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss\n",
    "        weight = weights.to(device)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "trainer = CustomTrainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85a527",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-21T08:20:28.358Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/pytorch_model.bin\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-21 08:20:33 (running for 00:00:00.16)\n",
      "Memory usage on this node: 16.1/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_3b454_00000 | RUNNING  | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |\n",
      "| _objective_3b454_00001 | PENDING  |                    | 0.131068  | 3.4486e-05  |              8 |           10 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-10-21 08:20:40 (running for 00:00:07.58)\n",
      "Memory usage on this node: 16.6/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_3b454_00000 | RUNNING  | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |\n",
      "| _objective_3b454_00001 | PENDING  |                    | 0.131068  | 3.4486e-05  |              8 |           10 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-10-21 08:20:45 (running for 00:00:12.58)\n",
      "Memory usage on this node: 16.0/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_3b454_00000 | RUNNING  | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |\n",
      "| _objective_3b454_00001 | PENDING  |                    | 0.131068  | 3.4486e-05  |              8 |           10 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-10-21 08:20:50 (running for 00:00:17.58)\n",
      "Memory usage on this node: 16.0/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_3b454_00000 | RUNNING  | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |\n",
      "| _objective_3b454_00001 | PENDING  |                    | 0.131068  | 3.4486e-05  |              8 |           10 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-21 08:20:55 (running for 00:00:22.58)\n",
      "Memory usage on this node: 16.0/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_3b454_00000 | RUNNING  | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |\n",
      "| _objective_3b454_00001 | PENDING  |                    | 0.131068  | 3.4486e-05  |              8 |           10 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-10-21 08:21:00 (running for 00:00:27.59)\n",
      "Memory usage on this node: 16.0/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------|\n",
      "| _objective_3b454_00000 | RUNNING  | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |\n",
      "| _objective_3b454_00001 | PENDING  |                    | 0.131068  | 3.4486e-05  |              8 |           10 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+\n",
      "\n",
      "\n",
      "Result for _objective_3b454_00000:\n",
      "  date: 2022-10-21_08-21-04\n",
      "  done: false\n",
      "  epoch: 2.91\n",
      "  eval_accuracy: 0.8\n",
      "  eval_f1: 0.0\n",
      "  eval_loss: 0.705464780330658\n",
      "  eval_runtime: 2.3124\n",
      "  eval_samples_per_second: 51.894\n",
      "  eval_steps_per_second: 6.487\n",
      "  experiment_id: d66192b2a5f444678c07664d0d27b90b\n",
      "  hostname: 3481a8a2ae33\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.3\n",
      "  objective: 0.8\n",
      "  pid: 4175666\n",
      "  time_since_restore: 28.770946502685547\n",
      "  time_this_iter_s: 28.770946502685547\n",
      "  time_total_s: 28.770946502685547\n",
      "  timestamp: 1666340464\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 3b454_00000\n",
      "  warmup_time: 0.0029556751251220703\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-10-21 08:21:09 (running for 00:00:36.46)\n",
      "Memory usage on this node: 15.9/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (1 PAUSED, 8 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |   eval_f1 |   eval_accuracy |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------|\n",
      "| _objective_3b454_00001 | RUNNING  | 172.17.0.3:4175666 | 0.131068  | 3.4486e-05  |              8 |           10 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00000 | PAUSED   | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |         0 |             0.8 |    0.705465 |    2.91 |                    1 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |           |                 |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-10-21 08:21:14 (running for 00:00:41.46)\n",
      "Memory usage on this node: 15.9/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (1 PAUSED, 8 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |   eval_f1 |   eval_accuracy |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------|\n",
      "| _objective_3b454_00001 | RUNNING  | 172.17.0.3:4175666 | 0.131068  | 3.4486e-05  |              8 |           10 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00000 | PAUSED   | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |         0 |             0.8 |    0.705465 |    2.91 |                    1 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |           |                 |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-10-21 08:21:19 (running for 00:00:46.46)\n",
      "Memory usage on this node: 15.9/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (1 PAUSED, 8 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |   eval_f1 |   eval_accuracy |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------|\n",
      "| _objective_3b454_00001 | RUNNING  | 172.17.0.3:4175666 | 0.131068  | 3.4486e-05  |              8 |           10 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00000 | PAUSED   | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |         0 |             0.8 |    0.705465 |    2.91 |                    1 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |           |                 |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-10-21 08:21:24 (running for 00:00:51.46)\n",
      "Memory usage on this node: 15.9/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (1 PAUSED, 8 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |   eval_f1 |   eval_accuracy |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------|\n",
      "| _objective_3b454_00001 | RUNNING  | 172.17.0.3:4175666 | 0.131068  | 3.4486e-05  |              8 |           10 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00000 | PAUSED   | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |         0 |             0.8 |    0.705465 |    2.91 |                    1 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |           |                 |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-10-21 08:21:29 (running for 00:00:56.47)\n",
      "Memory usage on this node: 15.9/31.1 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 16.0/16 CPUs, 1.0/1 GPUs, 0.0/17.26 GiB heap, 0.0/8.63 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /workspace/syc/BERT_classification_binary/test-results/tune_transformer_pbt\n",
      "Number of trials: 10/10 (1 PAUSED, 8 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "| Trial name             | status   | loc                |   w_decay |          lr |   train_bs/gpu |   num_epochs |   eval_f1 |   eval_accuracy |   eval_loss |   epoch |   training_iteration |\n",
      "|------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------|\n",
      "| _objective_3b454_00001 | RUNNING  | 172.17.0.3:4175666 | 0.131068  | 3.4486e-05  |              8 |           10 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00000 | PAUSED   | 172.17.0.3:4175666 | 0.0622085 | 1.04653e-05 |              4 |           18 |         0 |             0.8 |    0.705465 |    2.91 |                    1 |\n",
      "| _objective_3b454_00002 | PENDING  |                    | 0.249302  | 3.5349e-05  |              4 |           18 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00003 | PENDING  |                    | 0.144108  | 3.01024e-05 |              8 |            3 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00004 | PENDING  |                    | 0.212435  | 4.18747e-05 |              8 |           13 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00005 | PENDING  |                    | 0.0342197 | 4.80324e-05 |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00006 | PENDING  |                    | 0.104403  | 1.73035e-05 |              8 |            2 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00007 | PENDING  |                    | 0.179746  | 2.1645e-05  |              4 |            1 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00008 | PENDING  |                    | 0.0969584 | 3.36193e-05 |              8 |            8 |           |                 |             |         |                      |\n",
      "| _objective_3b454_00009 | PENDING  |                    | 0.0538494 | 2.27019e-05 |              8 |           10 |           |                 |             |         |                      |\n",
      "+------------------------+----------+--------------------+-----------+-------------+----------------+--------------+-----------+-----------------+-------------+---------+----------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with ray tune\n",
    "\n",
    "tune_config = {\n",
    "    \"per_device_eval_batch_size\": 8,\n",
    "    \"max_steps\": -1\n",
    "}\n",
    "\n",
    "# PopulationBasedTraining\n",
    "# worker might copy the model parameters from a better performing worker or explore new hyperparameters by changing the current values randomly\n",
    "# cf. ASHAScheduler\n",
    "\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=\"eval_f1\",\n",
    "    mode=\"max\",\n",
    "    perturbation_interval=1,\n",
    "    hyperparam_mutations={\n",
    "        \"num_train_epochs\": tune.randint(1, 20),\n",
    "        \"per_device_train_batch_size\": tune.choice([4, 8]),\n",
    "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
    "        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
    "        \"warmup_ratio\": tune.uniform(0.0, 0.3),\n",
    "        \"adam_beta1\": tune.loguniform(1e-2, 1),\n",
    "        \"adam_beta2\": tune.loguniform(1e-3, 1),\n",
    "        \"adam_epsilon\": tune.loguniform(1e-8, 1e-5),\n",
    "    }, # correct_bias = True 어떻게 설정..?\n",
    ")\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns={\n",
    "        \"weight_decay\": \"w_decay\",\n",
    "        \"learning_rate\": \"lr\",\n",
    "        \"per_device_train_batch_size\": \"train_bs/gpu\",\n",
    "        \"num_train_epochs\": \"num_epochs\",\n",
    "    },\n",
    "    metric_columns=[\"eval_f1\", \"eval_accuracy\", \"eval_loss\", \"epoch\", \"training_iteration\"]\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                           num_labels = 2,\n",
    "                                                           output_attentions = False,\n",
    "                                                           output_hidden_states = False)\n",
    "\n",
    "\n",
    "result = trainer.hyperparameter_search(\n",
    "    hp_space = lambda _: tune_config,\n",
    "    direction = \"maximize\",\n",
    "    backend=\"ray\",\n",
    "    reuse_actors = True,\n",
    "    n_trials=n_trials,\n",
    "    resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n",
    "    scheduler=scheduler,\n",
    "    keep_checkpoints_num=1,\n",
    "    checkpoint_score_attr=\"training_iteration\",\n",
    "    stop=None,\n",
    "    progress_reporter=reporter,\n",
    "    local_dir=\"./test-results\",\n",
    "    name=\"tune_transformer_pbt\",\n",
    "    log_to_file=True,\n",
    ")\n",
    "\n",
    "# local_dir = os.path.join(\"./\", model_name)\n",
    "\n",
    "# tune.run(trainer,\n",
    "#         local_dir = local_dir,\n",
    "#         resources_per_trial={\"cpu\" : 16, \"gpu\" : 1},\n",
    "#         config = config,\n",
    "#         num_samples = 1,\n",
    "#         scheduler = scheduler,\n",
    "#         progress_reporter = reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9aea0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.960840Z",
     "start_time": "2022-10-21T08:18:28.685Z"
    }
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80dbe63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.961194Z",
     "start_time": "2022-10-21T08:18:28.686Z"
    }
   },
   "outputs": [],
   "source": [
    "for n, v in result.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26870031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.961657Z",
     "start_time": "2022-10-21T08:18:28.687Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fd2c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.962002Z",
     "start_time": "2022-10-21T08:18:28.688Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae1e6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.962377Z",
     "start_time": "2022-10-21T08:18:28.688Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aecdc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.962980Z",
     "start_time": "2022-10-21T08:18:28.689Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = trainer.predict(test_dataset=test_dataset)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef40ce2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.963349Z",
     "start_time": "2022-10-21T08:18:28.690Z"
    }
   },
   "outputs": [],
   "source": [
    "label_test = list(pred.label_ids)\n",
    "pred_test = list(map(lambda x: x.index(max(x)), pred.predictions.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3999752c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.963689Z",
     "start_time": "2022-10-21T08:18:28.691Z"
    }
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(label_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87a4e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.964002Z",
     "start_time": "2022-10-21T08:18:28.692Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(label_test, pred_test)\n",
    "f1 = f1_score(label_test, pred_test)\n",
    "recall = recall_score(label_test, pred_test)\n",
    "precision = precision_score(label_test, pred_test)\n",
    "\n",
    "print(accuracy)\n",
    "print(f1)\n",
    "print(recall)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9d684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T08:19:51.964360Z",
     "start_time": "2022-10-21T08:18:28.693Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_path = \"test-model\"\n",
    "# trainer.model.save_pretrained(model_path)\n",
    "# tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3f419",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "https://bo-10000.tistory.com/154  \n",
    "https://huggingface.co/blog/ray-tune  \n",
    "https://docs.ray.io/en/latest/tune/examples/pbt_transformers.html  \n",
    "https://wood-b.github.io/post/a-novices-guide-to-hyperparameter-optimization-at-scale/#schedulers-vs-search-algorithms  \n",
    "https://docs.ray.io/en/latest/tune/api_docs/search_space.html  \n",
    "https://docs.ray.io/en/latest/tune/tutorials/tune-advanced-tutorial.html  \n",
    "https://docs.ray.io/en/latest/tune/api_docs/schedulers.html  \n",
    "https://blog.ml.cmu.edu/2018/12/12/massively-parallel-hyperparameter-optimization/  \n",
    "https://docs.ray.io/en/latest/tune/faq.html  \n",
    "https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#population-based-training-tune-schedulers-populationbasedtraining  \n",
    "https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.hyperparameter_search  \n",
    "https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#optuna-tune-search-optuna-optunasearch  \n",
    "https://kyunghyunlim.github.io/nlp/ml_ai/2021/09/22/hugging_face_5.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1aff3f",
   "metadata": {},
   "source": [
    "# Future Challenges\n",
    "2. 훈련 셋이 늘어나면서 성능이 어떻게 좋아지는지, hp조합에 따라 어떻게 좋아지는지 시각화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
